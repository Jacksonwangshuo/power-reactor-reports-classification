{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DF-ICF - Data Analysis\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Min percentage of docs in cluster where a term must appear to be chosen as a topic term\n",
    "min_term_df = 0.03    # ~0.03\n",
    "\n",
    "#file_start_text = \"Data_for_DF-ICF_\"    # A unique string that identifies a particular file as a cluster of documents\n",
    "file_start_text = \"issues\"\n",
    "\n",
    "data_dir = os.getcwd() + \"/\"\n",
    "\n",
    "#indir = \"/Volumes/IN-REGI-MerckProject38/Devon-Shuo/OutofShuoWang/DF-ICF/Scale(1-3)/bi/\" \n",
    "indir = \"C:/Users/wangs/OneDrive/桌面/\"\n",
    "outdir = os.getcwd() + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of POSTS in a CLUSTER with at least one occurence of a term\n",
    "def get_post_as_doc_freq(ck):\n",
    "    term_counts = dict()\n",
    "    num_posts = len(ck)\n",
    "    \n",
    "    for l, post in enumerate(ck):\n",
    "        tmp = str(post).replace(\",\", \"\").split()\n",
    "        \n",
    "        \n",
    "        single_terms = list(set(tmp))\n",
    "        \n",
    "        for i, wi in enumerate(single_terms):                        \n",
    "            if wi in term_counts.keys():\n",
    "                term_counts[wi] += 1\n",
    "            \n",
    "            else:\n",
    "                term_counts.update({str(wi): 1})\n",
    "      \n",
    "    return term_counts, num_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of CLUSTERS in which a term appears at least once\n",
    "def get_clus_as_doc_freq(c_fs):\n",
    "    clus_term_counts = dict()\n",
    "    \n",
    "    for k, ck_fs in c_fs.items():\n",
    "        tmp = list(ck_fs.keys())\n",
    "        all_term = list(set(tmp))    # Removes duplicate terms\n",
    "\n",
    "\n",
    "        for i, wi in enumerate(list(ck_fs.keys())):\n",
    "            if wi in clus_term_counts.keys():\n",
    "                clus_term_counts[wi] += 1\n",
    "            \n",
    "            else:\n",
    "                clus_term_counts.update({str(wi): 1})\n",
    "   \n",
    "    return clus_term_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Topic Diversity as the percentage of unique terms given all clusters top \"n\" topic terms\n",
    "def calculate_diversity(all_top_terms):\n",
    "    no_duplicate_terms = list(set(all_top_terms))\n",
    "    \n",
    "    total_topic_word_count = len(all_top_terms)    # This should be 250 in the case of 10 clusters and 25 topic words\n",
    "    unique_word_count = len(no_duplicate_terms)\n",
    "    \n",
    "    return float(unique_word_count/total_topic_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of POSTS in a CLUSTER with at least one occurence of both terms wi and wj\n",
    "def get_wi_wj_overlap_freq(wi, wj, ck):\n",
    "    num_overlaps = 0\n",
    "    num_posts = len(ck)\n",
    "    \n",
    "    for l, post in enumerate(ck):\n",
    "        tmp = str(post).replace(\",\", \"\").split()\n",
    "        single_terms = list(set(tmp))\n",
    "        \n",
    "        if (wi in single_terms) and (wj in single_terms):            \n",
    "            num_overlaps += 1\n",
    "            \n",
    "    return num_overlaps    # Returns the number of post co-occurrences within cluster ck for terms wi and wj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Normalized Pointwise Mutual Information for a given topic/cluster ck\n",
    "def calculate_npmi(corp_dfs, ck_top_terms, corp_size, corp_texts):    \n",
    "    num_top_terms = len(ck_top_terms)\n",
    "    D = int(corp_size)\n",
    "    TC_k = 0.0\n",
    "    \n",
    "    for i, dfitf_tuple in enumerate(ck_top_terms):\n",
    "        t_wi = str(dfitf_tuple[0])    # The actual string term wj\n",
    "        \n",
    "        try:\n",
    "            D_wi= int(corp_dfs[t_wi])    # Number of documents in the input corpus with wi\n",
    "\n",
    "        except (KeyError):\n",
    "            D_wi = 0\n",
    "                \n",
    "        j = i + 1\n",
    "        \n",
    "        while (j < (num_top_terms)) and (j > i):            \n",
    "            t_wj = str(tuple(ck_top_terms[j])[0])   # The actual string term wj\n",
    "            \n",
    "            try:\n",
    "                D_wj = int(corp_dfs[t_wj])    # Number of documents in the input corpus with wj\n",
    "            \n",
    "            except (KeyError):\n",
    "                D_wj = 0\n",
    "            \n",
    "            D_wi_wj = get_wi_wj_overlap_freq(t_wi, t_wj, corp_texts)  # Number of documents in the input corpus with wi and wj\n",
    "            \n",
    "            if D_wi_wj == 0:  # In the case there is no term overlap for topic terms wi and wj\n",
    "                f_wi_wj = -1\n",
    "            \n",
    "            else:    # Otherwise calculate the NPMI with the previously determined frequencies\n",
    "                f_wi_wj = -1 + (np.log(D_wi)+np.log(D_wj)-2.0*np.log(D))/(np.log(D_wi_wj)-np.log(D))\n",
    "            \n",
    "            TC_k += f_wi_wj    # Sum across the top 10 terms in a topic/cluster ck\n",
    "            j += 1\n",
    "        \n",
    "    return TC_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_metrics(clus_dfs, clus_itfs, clus_dfitfs, clus_texts, clus_sizes):    \n",
    "    num_top_terms_coh = 10\n",
    "    num_top_terms_div = 25\n",
    "    \n",
    "    num_clusters = len(list(clus_sizes.keys()))\n",
    "    all_top_terms = list()\n",
    "    clus_TCs = dict()\n",
    "    corpus_term_dfs = dict()\n",
    "    \n",
    "    # Make a flat list of all documents in the corpus, effectively combines all clusters into a single corpus list of posts\n",
    "    flat_corpus = [entry for sublist in list(clus_texts.values()) for entry in sublist]\n",
    "    \n",
    "    # For each post in the entire corpus\n",
    "    for k, doc in enumerate(flat_corpus):\n",
    "        for term in str(doc).split():    # For each term in each document in the corpus\n",
    "            if term in corpus_term_dfs.keys():\n",
    "                corpus_term_dfs[term] += 1\n",
    "\n",
    "            else:\n",
    "                corpus_term_dfs.update({str(term): int(1)})\n",
    "    \n",
    "    # Calculate the TC for each cluster\n",
    "    for k in clus_sizes.keys():        \n",
    "        ck_top_terms = list(clus_dfitfs[k])\n",
    "        \n",
    "        all_top_terms.extend(list(ck_top_terms))    # Make a list of ALL top terms selected from all topics for TD calculation\n",
    "        \n",
    "        # Considering the entire corpus (Blei's Method):\n",
    "        TC_ck = float(calculate_npmi(dict(corpus_term_dfs), list(ck_top_terms[:num_top_terms_coh]), int(len(corpus_term_dfs)), list(flat_corpus)))\n",
    "        \n",
    "        TC_ck /= (num_top_terms_coh*(num_top_terms_coh-1)/2)    # This is where the (1/45) is applied\n",
    "        \n",
    "        print(\"Topic: \", k)\n",
    "        print(\"TC_ck = \", TC_ck)\n",
    "        \n",
    "        clus_TCs.update({str(k): float(TC_ck)})        \n",
    "            \n",
    "    # The overall TC is then calculated as the average TC for each topic/cluster\n",
    "    TC = (1/num_clusters) * sum(list(clus_TCs.values()))\n",
    "    # TC = np.mean(list(clus_TCs.values()))    # This gives the same values as the above line\n",
    "    TD = float(calculate_diversity(all_top_terms))\n",
    "    \n",
    "    print(\"\\nTopic Coherence: \", TC)\n",
    "    print(\"Topic Diversity: \", TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine topic terms using DF-ITF, where each POST is a DOCUMENT and each CLUSTER is a TOPIC\n",
    "def calculate_dfitf(indf_dict):\n",
    "    df_clus_dict = dict()\n",
    "    itf_clus_dict = dict()\n",
    "    clus_texts = dict()\n",
    "    clus_dfitfs = dict()\n",
    "    clus_sizes = dict()\n",
    "\n",
    "    for k, ck_df in indf_dict.items():\n",
    "        ck_tex = ck_df[ck_df.columns[0]].tolist()    # Get all posts in cluster ck as a list of strings\n",
    "        #print(ck_df.columns[7])\n",
    "        temp_dfs, ck_size = get_post_as_doc_freq(ck_tex)\n",
    "\n",
    "        df_clus_dict.update({str(k): dict(temp_dfs)})\n",
    "        clus_texts.update({str(k): list(ck_tex)})\n",
    "        clus_sizes.update({str(k): int(ck_size)})\n",
    "\n",
    "    clus_doc_freqs = get_clus_as_doc_freq(df_clus_dict)\n",
    " \n",
    "    for k, ck_dfs in df_clus_dict.items():\n",
    "        term_dfitfs = dict()\n",
    "        min_count_topic_terms = dict()\n",
    "        ck_size = int(clus_sizes[k])\n",
    "\n",
    "        for i, (wi, df) in enumerate(ck_dfs.items()):\n",
    "            wi_df = float(df/clus_sizes[k])    # Adjusted for cluster/topic size\n",
    "            # wi_df = float(df)\n",
    "            wi_itf = float(np.log(((num_clusters)/(clus_doc_freqs[wi]))))\n",
    "\n",
    "            wi_dfitf = float(wi_df*wi_itf)\n",
    "\n",
    "            if wi in term_dfitfs.keys():\n",
    "                term_dfitfs[wi] += float(wi_dfitf)\n",
    "\n",
    "            else:\n",
    "                term_dfitfs.update({str(wi): float(wi_dfitf)})\n",
    "\n",
    "        # Uncomment the next two lines to take average instead of summation\n",
    "        # for i, (wi, df) in enumerate(ck_dfs.items()):\n",
    "            # term_dfitfs[wi] /= int(df)\n",
    "\n",
    "        for wi, dfitf in term_dfitfs.items():\n",
    "            wi_df = float(ck_dfs[wi])\n",
    "            \n",
    "            if wi_df >= (ck_size*min_term_df):\n",
    "                min_count_topic_terms.update({str(wi): float(dfitf)})\n",
    "            \n",
    "        clus_dfitfs.update({str(k): sorted(min_count_topic_terms.items(), key=lambda item: item[1], reverse=True)})\n",
    "\n",
    "    for k, ck_dfitfs in clus_dfitfs.items():\n",
    "        print(\"\\nTopic \", k, \":\")    #TEMP\n",
    "        print(ck_dfitfs[:20])    #TEMP\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return dict(df_clus_dict), dict(itf_clus_dict), dict(clus_dfitfs), dict(clus_texts), dict(clus_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  1 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  2 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  3 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  4 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  5 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  6 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  7 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  8 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "Topic  9 :\n",
      "[('increase', -inf), ('power', -inf), ('alert', -inf), ('conservative', -inf), ('oos', -inf), ('tower', -inf), ('transformer', -inf), ('cool', -inf), ('one', -inf), ('supply', -inf), ('hold', -inf), ('to', -inf), ('due', -inf), ('outage', -inf), ('maintenance', -inf), ('in', -inf), ('condenser', -inf), ('progress', -inf), ('planned', -inf), ('reduced', -inf)]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangs\\AppData\\Local\\Temp\\ipykernel_3696\\2168047461.py:28: RuntimeWarning: divide by zero encountered in log\n",
      "  wi_itf = float(np.log(((num_clusters)/(clus_doc_freqs[wi]))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic:  0\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  1\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  2\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  3\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  4\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  5\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  6\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  7\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  8\n",
      "TC_ck =  -0.22516620002950802\n",
      "Topic:  9\n",
      "TC_ck =  -0.22516620002950802\n",
      "\n",
      "Topic Coherence:  -0.22516620002950802\n",
      "Topic Diversity:  0.1\n"
     ]
    }
   ],
   "source": [
    "# Initialize indf dictionary and cluster counter\n",
    "indf_dict = dict()\n",
    "num_clusters = 0\n",
    "\n",
    "for file in os.listdir(indir):\n",
    "    if (file.endswith(\".csv\")) and (file.startswith(str(file_start_text))):\n",
    "        df = pd.read_csv(str(indir) + str(file), encoding='utf-8')\n",
    "        #clus_num = re.search(r\"(\\d+)\", str(file))\n",
    "        #print(clus_num)\n",
    "        #indf_dict.update({str(clus_num.group(1)): df})\n",
    "        for i in range(10):\n",
    "            indf_dict.update({str(i): df})\n",
    "        #num_clusters += 1\n",
    "\n",
    "df_clus_dict, itf_clus_dict, clus_dfitfs, clus_texts, clus_sizes = calculate_dfitf(dict(indf_dict))\n",
    "\n",
    "\n",
    "calculate_topic_metrics(dict(df_clus_dict), dict(itf_clus_dict), dict(clus_dfitfs), dict(clus_texts), dict(clus_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>increase power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conservative operations alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one cool tower transformer oos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>power supply alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hold power due to s g condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>waterbox cleaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>waterbox cleaning rod pattern adjustment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>will be come offline 1500 edt to repair a stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>will conduct a turbine valve freedom test today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>yellow grid due to offsite alignment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1586 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Reason_text\n",
       "0                                        increase power\n",
       "1                         conservative operations alert\n",
       "2                        one cool tower transformer oos\n",
       "3                                    power supply alert\n",
       "4                       hold power due to s g condition\n",
       "...                                                 ...\n",
       "1581                                  waterbox cleaning\n",
       "1582           waterbox cleaning rod pattern adjustment\n",
       "1583  will be come offline 1500 edt to repair a stat...\n",
       "1584    will conduct a turbine valve freedom test today\n",
       "1585               yellow grid due to offsite alignment\n",
       "\n",
       "[1586 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
